<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example 001: Periodic Advection · CLIMA</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../../index.html"><img class="logo" src="../../../assets/logo.svg" alt="CLIMA logo"/></a><h1>CLIMA</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../../index.html">Home</a></li><li><span class="toctext">Common</span><ul><li><a class="toctext" href="../../../Common/MoistThermodynamics.html">MoistThermodynamics</a></li></ul></li><li><span class="toctext">Utilites</span><ul><li><a class="toctext" href="../../../Utilities/RootSolvers.html">RootSolvers</a></li></ul></li><li><span class="toctext">Atmos</span><ul><li><a class="toctext" href="../../../Atmos/SurfaceFluxes.html"><code>SurfaceFluxes</code></a></li><li><a class="toctext" href="../../../Atmos/TurbulenceConvection.html"><code>TurbulenceConvection</code></a></li><li><a class="toctext" href="../../../Atmos/EDMFEquations.html">Eddy-Diffusivity Mass-Flux (EDMF) equations</a></li><li><a class="toctext" href="../../../Atmos/Microphysics.html">Microphysics</a></li></ul></li><li><a class="toctext" href="../../../ODESolvers.html">ODESolvers</a></li><li><a class="toctext" href="../../../LinearSolvers.html">LinearSolvers</a></li><li><a class="toctext" href="../../../Mesh.html">Mesh</a></li><li><a class="toctext" href="../../../Arrays.html">Arrays</a></li><li><a class="toctext" href="../../../DGmethods_old.html">DGmethods_old</a></li><li><a class="toctext" href="../../../InputOutput.html">InputOutput</a></li><li><span class="toctext">Developer docs</span><ul><li><a class="toctext" href="../../../CodingConventions.html">Coding Conventions</a></li><li><a class="toctext" href="../../../AcceptableUnicode.html">Acceptable Unicode characters</a></li><li><a class="toctext" href="../../../VariableList.html">CliMA Variable List</a></li></ul></li><li><span class="toctext">Balance Law Examples</span><ul><li><a class="toctext" href="../../../BalanceLawOverview.html">DG Balance Law Method</a></li><li class="current"><a class="toctext" href="ex_001_periodic_advection.html">Example 001: Periodic Advection</a><ul class="internal"><li><a class="toctext" href="#Introduction-1">Introduction</a></li><li><a class="toctext" href="#Commented-Program-1">Commented Program</a></li><li><a class="toctext" href="#ex_001_periodic_advection-plain-program-1">Plain Program</a></li></ul></li><li><a class="toctext" href="ex_002_solid_body_rotation.html">Example 002: Solid Body Rotation</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Balance Law Examples</li><li><a href="ex_001_periodic_advection.html">Example 001: Periodic Advection</a></li></ul><a class="edit-page" href="https://github.com/climate-machine/CLIMA/blob/master/examples/DGmethods_old/ex_001_periodic_advection.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Example 001: Periodic Advection</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Example-001:-Periodic-Advection-1" href="#Example-001:-Periodic-Advection-1">Example 001: Periodic Advection</a></h1><div class="admonition jupyter"><div class="admonition-title">Jupyter</div><div class="admonition-text"><p>This example is also available as a Jupyter notebook: <a href="https://nbviewer.jupyter.org/github/climate-machine/CLIMA/blob/gh-pages/TRAVIS_TAG/examples/DGmethods_old/generated/ex_001_periodic_advection.html"><code>ex_001_periodic_advection.ipynb</code></a></p></div></div><p>Key ideas of this tutorial:</p><ul><li>Setting up PDE</li><li>Defining a numerical flux</li><li>Defining finite element mesh</li><li>Using the ODE solving framework</li><li>Using VTK visualization</li></ul><h2><a class="nav-anchor" id="Introduction-1" href="#Introduction-1">Introduction</a></h2><p>In this example we will solve the constant coefficient advection equation on a periodic domain; the domain is taken to be the unit square or cube depending on whether the problem is two- or three-dimensional.</p><p>The partial differential equation we wish to solve is</p><div>\[ \frac{\partial q}{\partial t} + \nabla \cdot (\vec{u} q) = 0,\]</div><p>where <span>$q$</span> is the advected scalar quantity and <span>$\vec{u}$</span> is the constant velocity field. The quantity <span>$\vec{u} q$</span> is more generally called the flux and denoted in the tutorial below as <span>$\boldsymbol{F}(q) = \vec{u} q$</span>.</p><p>Below is a program interspersed with comments. The full program, without comments, can be found in the next <a href="ex_001_periodic_advection.html#ex_001_periodic_advection-plain-program-1">section</a>.</p><h2><a class="nav-anchor" id="Commented-Program-1" href="#Commented-Program-1">Commented Program</a></h2><h3><a class="nav-anchor" id="Preliminaries-1" href="#Preliminaries-1">Preliminaries</a></h3><p>Load in modules needed for solving the problem</p><pre><code class="language-julia">using MPI
using CLIMA.Mesh.Topologies
using CLIMA.Mesh.Grids
using CLIMA.DGBalanceLawDiscretizations
using CLIMA.MPIStateArrays
using CLIMA.LowStorageRungeKuttaMethod
using CLIMA.ODESolvers
using CLIMA.GenericCallbacks
using CLIMA.VTK
using LinearAlgebra
using Logging
using Dates
using Printf
using StaticArrays</code></pre><p>Start up MPI if this has not already been done</p><pre><code class="language-julia">MPI.Initialized() || MPI.Init()</code></pre><p>define the velocity field for advection</p><pre><code class="language-julia">const uvec = (1, 2, 3)</code></pre><h3><a class="nav-anchor" id="Physical-Flux-1" href="#Physical-Flux-1">Physical Flux</a></h3><p>Now we define a function which given a value for <span>$q$</span> computes the physical flux <span>$\boldsymbol{F} = \vec{u} q$</span>. Since we only have a single state, <span>$q$</span>, the state will come in as an <code>MVector</code> of length <code>1</code> and the flux to fill as an <code>MMatrix</code> of size <code>(3, 1)</code>.</p><p>Note: for two-dimensional simulations the flux <code>MMatrix</code> will also be of size <code>(3, 1)</code> but the function need only fill the first two rows</p><pre><code class="language-julia">function advectionflux!(F, state, _...)
  DFloat = eltype(state) # get the floating point type we are using
  @inbounds begin
    q = state[1]
    F[:, 1] = SVector{3, DFloat}(uvec) * q
  end
end</code></pre><h3><a class="nav-anchor" id="Numerical-Flux-1" href="#Numerical-Flux-1">Numerical Flux</a></h3><p>In the discontinuous Galerkin method the continuity of the solution across element interfaces is imposed weakly through the use of a numerical flux. The numerical flux is a function that given the solution state on either side of an interface returns a unique value approximating <span>$\boldsymbol{F}\cdot \vec{n}$</span> on the interface:</p><div>\[f^{*} = f^{*}(q^{-}, q^{+}; \vec{n}).\]</div><p>We call the two sides of the interface the &quot;minus side&quot; and &quot;plus side&quot; hence the <span>$\pm$</span> superscripts in <span>$q$</span> in the notation above; the choice of which element is on the minus side and plus side is arbitrary. Here <span>$\vec{n}$</span> is a unit normal to the interface and is typically taken to point from the minus side to the plus side. The numerical flux is required to be symmetric with respect to <span>$q^{-}$</span> and <span>$q^{+}$</span>:</p><div>\[f^{*}(q^{-}, q^{+}; \vec{n}) = f^{*}(q^{+}, q^{-}; \vec{n}).\]</div><p>and consistent with the physical flux in the sense that</p><div>\[\boldsymbol{F}(q) \cdot \vec{n} = f^{*}(q, q; \vec{n}).\]</div><p>Taken together these two conditions also imply that</p><div>\[f^{*}(q^{-}, q^{+}; \vec{n}^{-}) = -f^{*}(q^{+}, q^{-}; \vec{n}^{+}),\]</div><p>that is <span>$f^{*}$</span> is skew-symmetry with respect to the unit normals <span>$\vec{n}^{+} = -\vec{n}^{-}$</span>.  The choice of numerical flux has important implications for the stability of the method. Though it is beyond the scope of these tutorials to dive into this in detail, often the &quot;best&quot; numerical fluxes are the ones that are constructed specifically for given set of equations by solving the Riemann problem; the Riemann problem is an initial value problem where the initial data are piecewise constant with a single discontinuity.</p><p>In the CLIMA balance law solver the numerical flux function is a user-defined function that fills in an <code>MVector</code> for the numerical flux given two states, the &quot;viscous state&quot;, a unit normal to the face, the simulation time, and a user-defined auxiliary state; the viscous and auxiliary states will be discussed in a subsequent examples. In the function below <code>F</code> is the numerical flux to fill, <code>nM</code> is the unit normal pointing away from the minus side and toward the plus side, <code>QM</code> and <code>QP</code> are <code>MVector</code>s of the solution state on the minus and plus sides of the interface, <code>viscM</code> and <code>viscP</code> are the viscous states on the minus and plus sides, <code>auxM</code> and <code>auxP</code> are the user-defined auxiliary state values on the minus and plus sides, and <code>t</code> is the simulation time.</p><p>For linear advection the solution to the Riemann problem is trivial, since if <span>$\vec{n}^{-} \cdot \vec{u} ≥ 0$</span> the state <span>$q$</span> is being advected from the minus side to the plus side otherwise the reverse occurs. Thus the upwind numerical flux for advection is</p><div>\[f^{*}(q^{-}, q^{+}; \vec{n}^{-}) =
\begin{cases}
  \vec{n}^{-}\cdot\vec{u} \; q^{-}, &amp;\text{ if } \vec{n} \cdot \vec{u} ≥ 0,\\
  \vec{n}^{-}\cdot\vec{u} \; q^{+}, &amp;\text{ otherwise.}
\end{cases}\]</div><p>This is done in the following function</p><pre><code class="language-julia">function upwindflux!(fs, nM, stateM, viscM, auxM, stateP, viscP, auxP, t)
  DFloat = eltype(fs)
  @inbounds begin
    # determine the advection speed and direction
    un = dot(nM, DFloat.(uvec))
    qM = stateM[1]
    qP = stateP[1]
    # Determine which state is &quot;upwind&quot; of the minus side
    fs[1] = un ≥ 0 ? un * qM : un * qP
  end
end</code></pre><p>In later examples we will demonstrate how to use the Rusanov flux which is included in the <code>CLIMA.DGBalanceLawDiscretizations.NumericalFluxes</code> submodule. This is a more general-purpose flux which approximates the solution Riemann problem by using an average of the flux on either side of the interface with additional dissipation added based on the local wave speed.</p><h3><a class="nav-anchor" id="Initial-Condition-1" href="#Initial-Condition-1">Initial Condition</a></h3><p>In this example we take the initial condition to be</p><div>\[q(\vec{x}, t=0) = \prod_{i=1}^{d} \exp(\sin(2\pi x_{i})),\]</div><p>where <span>$d$</span> is the dimensionality of the problem. To use this initial condition we need a function that given <span>$\vec{x}$</span> sets <span>$q$</span>.</p><p>The initial condition is set by the solver through a function which takes <span>$q$</span> as an <code>MVector</code> to initialize based on the pointwise coordinate location <code>(x_1, x_2, x_3)</code>.</p><p>Note: The initial condition will always be called as though the dimensionality of the problem is 3. For the domain used below <code>x_3 = 0</code> when the problem is actually two-dimensional; since when <span>$x_3 = 0$</span> the function <span>$\exp(\sin(2\pi x_{3})) = 1$</span> we can safely assume the dimensionality is always <span>$3$</span> in our implication of the initial condition.</p><p>Note: The last argument needs to be caught but not used for this example</p><pre><code class="language-julia">function initialcondition!(Q, x_1, x_2, x_3, _...)
  @inbounds Q[1] = exp(sin(2π * x_1)) * exp(sin(2π * x_2)) * exp(sin(2π * x_3))
end</code></pre><h3><a class="nav-anchor" id="Exact-Solution-1" href="#Exact-Solution-1">Exact Solution</a></h3><p>For periodic constant-velocity advection the exact solution is trivial to compute. Assuming that <span>$\phi(x)$</span> is the periodically replicated initial condition, the analytic solution is</p><div>\[q(\vec{x}, t) = \phi(\vec{x} - \vec{u} t).\]</div><p>This will be useful later since it will allow us to check our work by computing the error in our solution and estimating the convergence rate.</p><p>For a general initial condition on the unit domain the following function can be used:</p><pre><code class="language-julia">function exactsolution!(dim, Q, t, x_1, x_2, x_3, _...)
  @inbounds begin
    DFloat = eltype(Q)

    # trace back the point (x_1, x_2, x_3) in the velocity field and
    # determine where in our &quot;original&quot; [0, L_1] X [0, L_2] X [0, L_3] domain
    # this point is located
    y_1 = mod(x_1 - DFloat(uvec[1]) * t, 1)
    y_2 = mod(x_2 - DFloat(uvec[2]) * t, 1)

    # if we are really just 2-D we do not want to change the x_3 coordinate
    y_3 = dim == 3 ? mod(x_3 - DFloat(uvec[3]) * t, 1) : x_3

    initialcondition!(Q, y_1, y_2, y_3)
  end
end</code></pre><p>The input argument <code>dim</code> is the &quot;real&quot; dimensionality of the problem and is needed in case <code>uvec[3] != 0</code>.</p><h3><a class="nav-anchor" id="Initialize-the-DG-Method-1" href="#Initialize-the-DG-Method-1">Initialize the DG Method</a></h3><p>We are now at the point that we can initialize the structure for the DG method.  For convenience we define a function that initializes the DG method over a given MPI communicator <code>mpicomm</code>, for a given <code>polynomialorder</code>, using <code>dim</code> dimensions. The mesh used will be <code>Ne</code> x <code>Ne</code> elements when <code>dim == 2</code> and <code>Ne</code> x <code>Ne</code> x <code>Ne</code> elements when <code>dim == 3</code>. The floating point type of the computation is <code>DFloat</code> and whether the CPU or GPU is used is determined by <code>ArrayType</code>; <code>ArrayType === Array</code> is for the CPU and <code>ArrayType === CuArray</code> is for NVIDIA GPUs.</p><p>Note: This whole code chunk is in a function block</p><pre><code class="language-julia">function setupDG(mpicomm, dim, Ne, polynomialorder, DFloat=Float64,
                 ArrayType=Array)

  @assert ArrayType === Array</code></pre><p>We will use the <code>BrickTopology</code> from <code>CLIMA.Mesh.Topologies</code> to define the mesh. The &quot;topology&quot; in CLIMA is the element connectivity information (e.g., neighbouring elements and interface data) along with coordinate locations for corners of the elements. The <code>BrickTopology</code> creates a regular mesh of a rectangular or regular hexahedral domain. This is done by specifying the coordinate points of the element corners along each dimension. Here, we want to mesh the unit square or cube with <code>Ne</code> elements in each dimension, thus we specify the following <code>Tuple</code> of <code>range</code>s:</p><pre><code class="language-julia">  brickrange = (range(DFloat(0); length=Ne+1, stop=1), # x_1 corner locations
                range(DFloat(0); length=Ne+1, stop=1), # x_2 corner locations
                range(DFloat(0); length=Ne+1, stop=1)) # x_3 corner locations</code></pre><p>these coordinates will be combined in a tensor product fashion to define the element corners.</p><p>By default the <code>BrickTopology</code> is not periodic, so we need to define a <code>Tuple</code> of boolean defining which dimensions are periodic.</p><pre><code class="language-julia">  periodicity = (true, true, true)</code></pre><p>Note: We have defined both the <code>brickrange</code> and <code>periodicity</code> as though we are working in three-dimensions, and in when in two-dimensions we will discard the third element of the <code>Tuple</code>; this could also be done from the start by using the <code>ntuple</code> function.</p><p>Using <code>brickrange</code> and <code>periodicity</code> we can now initialize the topology using the <code>BrickTopology</code> constructor. This will both create the topology as well as do the partitioning of the elements across the MPI ranks available in the mpi communicator <code>mpicomm</code></p><pre><code class="language-julia">  topology = BrickTopology(mpicomm, brickrange[1:dim];
                           periodicity=periodicity[1:dim])</code></pre><p>The topology only has element connectivity and corner information, thus we still need to create a grid (or mesh) of degrees of freedom. In CLIMA the so-called discontinuous spectral element grid is used (aka tensor-product quadrilateral and hexahedral elements with Legendre-Gauss-Lobatto interpolation and quadrature weights). Given a topology and polynomial order we can create the grid of degrees of free using</p><pre><code class="language-julia">  grid = DiscontinuousSpectralElementGrid(topology; polynomialorder =
                                          polynomialorder, FloatType = DFloat,
                                          DeviceArray = ArrayType,)</code></pre><p>Note: This constructor also takes in a <code>FloatType</code> which specifies the floating point type to be used (e.g., for the coordinate points and geometry metric terms). The argument <code>ArrayType</code> is used to determine the compute device to use (i.e., <code>Array</code> will signify the CPU is being used and <code>CuArray</code> will signal that an NVIDIA GPU is being used).</p><p>We can now define the discretization from the <code>grid</code> using the physical flux <code>advectionflux!</code> and numerical flux <code>upwindflux!</code> defined above; we only have a single state variable <span>$q$</span> hence <code>length_state_vector = 1</code></p><pre><code class="language-julia">  spatialdiscretization = DGBalanceLaw(grid = grid, length_state_vector = 1,
                                       flux! = advectionflux!,
                                       numerical_flux! = upwindflux!)</code></pre><p>(end of function)</p><pre><code class="language-julia">end</code></pre><h3><a class="nav-anchor" id="Initializing-and-run-the-DG-method-1" href="#Initializing-and-run-the-DG-method-1">Initializing and run the DG method</a></h3><p>Note: This whole code chunk is in a <code>let</code> block</p><pre><code class="language-julia">let</code></pre><p>We will just use the whole MPI communicator</p><pre><code class="language-julia">  mpicomm = MPI.COMM_WORLD</code></pre><p>Since this is an MPI enabled code, we use the Julia logging functionality to ensure that only one MPI rank prints to the screen. Namely, MPI rank 0 does all the logging and all other ranks dump their ouput to <code>devnull</code>.</p><pre><code class="language-julia">  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)</code></pre><p>Note: The <code>NullLogger</code> should not be used because if any MPI functions are called in a logging block deadlock will occur since <code>NullLogger</code> code is not executed.</p><p>Dimensionality to run</p><pre><code class="language-julia">  dim = 2</code></pre><p>Mesh size along each dimension</p><pre><code class="language-julia">  Ne = 20</code></pre><p>order of polynomials to use</p><pre><code class="language-julia">  polynomialorder = 4</code></pre><p>Setup the DG discretization</p><pre><code class="language-julia">  spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)</code></pre><p>Given the <code>spatialdiscretization</code> and the <code>initialcondition!</code> function we can create and initialize storage for the solution. This is an MPI-aware array</p><pre><code class="language-julia">  Q = MPIStateArray(spatialdiscretization, initialcondition!)</code></pre><p>A VTK file, which can be viewed in <a href="https://www.paraview.org/">ParaView</a> or <a href="https://wci.llnl.gov/simulation/computer-codes/visit">VisIt</a>, can be generated with the following command (the last <code>Tuple</code> gives strings for the names of the state fields)</p><pre><code class="language-julia">  filename = @sprintf(&quot;initialcondition_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))</code></pre><p>Note: Currently the <code>writevtk</code> function writes one file for each MPI rank, and the user is responsible for opening each of the files to &quot;stitch&quot; together the image.</p><p>In order to run the simulation we need to use an ODE solver. In this example we will use a low storage Runge-Kutta method which can be initialized with a spatial discretization, solution vector (not stored but used to define needed auxiliary arrays), initial solution time, and a time step size; this particular Runge-Kutta method uses a fixed time step.</p><p>Since we are using a regular mesh, with a constant wave speed, a &quot;CFL&quot; restriction for the mesh is</p><pre><code class="language-julia">  h = 1 / Ne                           # element size
  CFL = h / maximum(abs.(uvec[1:dim])) # time to cross the element once
  dt = CFL / polynomialorder^2         # DG time step scaling (for this
                                       # particular RK scheme could go with a
                                       # factor of ~2 larger time step)
  lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)</code></pre><p>Here we run the ODE solver until the final time <code>timeend</code> using <code>Q</code> as the initial condition <code>Q</code>. The solution will be updated in place so that the final solution will also be stored in <code>Q</code>.</p><pre><code class="language-julia">  finaltime = 1.0
  solve!(Q, lsrk; timeend = finaltime)</code></pre><p>The final solution can be visualized in a similar manner to the initial condition</p><pre><code class="language-julia">  filename = @sprintf(&quot;finalsolution_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))</code></pre><p>Using the <code>finaltime</code> and <code>exactsolution!</code> we can calculate the exact solution</p><pre><code class="language-julia">  Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
    exactsolution!(dim, Qin, finaltime, x, y, z)
  end</code></pre><p>and then compute the error by evaluating the Euclidean distance between the computed solution <code>Q</code> and the exact solution <code>Qe</code></p><pre><code class="language-julia">  error = euclidean_distance(Q, Qe)
  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Run with
                   dim              = %d
                   Ne               = %d
                   polynomial order = %d
                   error            = %e
                   &quot;&quot;&quot;, dim, Ne, polynomialorder, error)
  end
end</code></pre><pre><code class="language-none">┌ Info: Run with
│ dim              = 2
│ Ne               = 20
│ polynomial order = 4
└ error            = 3.219188e-06</code></pre><h3><a class="nav-anchor" id="Using-ODE-solver-callback-functions-1" href="#Using-ODE-solver-callback-functions-1">Using ODE solver callback functions</a></h3><p>The above simulation run with <code>solve!</code> runs from the initial time to the final time. The ODE solver framework in CLIMA gives functionality that allows the user to <em>inject</em> code into the solver during execution. Here we show how to use some of the generic callback functions provided to</p><ul><li>Save diagnostic information</li><li>display runtime simulation information</li><li>save VTK files during the simulation</li></ul><p>Note: This whole code chunk is in a <code>let</code> block</p><pre><code class="language-julia">let</code></pre><p>code is the same as above until the <code>solve!</code> call</p><pre><code class="language-julia">  mpicomm = MPI.COMM_WORLD
  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)
  dim = 2
  Ne = 20
  polynomialorder = 4
  spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)
  Q = MPIStateArray(spatialdiscretization, initialcondition!)
  filename = @sprintf(&quot;initialcondition_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))
  h = 1 / Ne
  CFL = h / maximum(abs.(uvec[1:dim]))
  dt = CFL / polynomialorder^2
  lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)
  finaltime = 1.0</code></pre><p>The ODE solver callback functions are called both before the ODE solver begins and then after each time step.</p><p>For instance if a user wanted to store the norm of the solution every time step the following callback could be used</p><pre><code class="language-julia">  store_norm_index = 0
  normQ = Array{Float64}(undef, ceil(Int, finaltime / dt))
  function cb_store_norm()
    store_norm_index += 1
    normQ[store_norm_index] = norm(Q)
    nothing
  end</code></pre><p>Note: that callbacks must return either <code>nothing</code> or <code>0</code> if the ODE solver should continue, <code>1</code> is the ODE solver should stop after all the callbacks have executed, or <code>2</code> is the time stepping should immediately stop with no further callbacks executed.</p><p>Several generic callbacks are provided in the <code>CLIMA.GenericCallbacks</code> submodule. For instance, the <code>EveryXSimulationSteps</code> callbacks will execute every <code>X</code> time steps. This could be used to say write VTK output every <code>20</code> time steps</p><pre><code class="language-julia">  vtk_step = 0
  mkpath(&quot;vtk&quot;)
  cb_vtk = GenericCallbacks.EveryXSimulationSteps(20) do
    vtk_step += 1
    filename = @sprintf(&quot;vtk/advection_mpirank%04d_step%04d&quot;,
                         MPI.Comm_rank(mpicomm), vtk_step)
    writevtk(filename, Q, spatialdiscretization,
                                         (&quot;q&quot;,))
    nothing
  end</code></pre><p>Another provided generic callback is <code>EveryXWallTimeSeconds</code> which will be called every <code>X</code> seconds of wall clock time (as opposed to simulation time). This could be used to dump diagnostic information about the simulation. In this case we display the norm of the simulation time, the run time, and the norm of the solution.</p><p>One unique feature of this call back is that it takes in a single optional argument <code>init</code> which allows the ODE solver to call the callback for initialization; all callbacks get called for initialization with a single boolean argument set to <code>true</code>, but this occurs in a <code>try/catch</code> statement in case the callback does not require initialization (such as the two above).</p><pre><code class="language-julia">  starttime = Ref(now())
  cb_info = GenericCallbacks.EveryXWallTimeSeconds(1, mpicomm) do (init=false)
    if init
      starttime[] = now()
    else
      with_logger(mpi_logger) do
        @info @sprintf(&quot;&quot;&quot;Update
                       simtime = %.16e
                       runtime = %s
                       norm(Q) = %.16e&quot;&quot;&quot;, ODESolvers.gettime(lsrk),
                       Dates.format(convert(Dates.DateTime,
                                            Dates.now()-starttime[]),
                                    Dates.dateformat&quot;HH:MM:SS&quot;),
                       norm(Q))
      end
    end
  end</code></pre><p>Note that this callback also takes in the MPI communicator. This is necessary because the callback needs to execute an <code>MPI.Allreduce</code> to ensure that all the MPI ranks are using the same global run time.</p><p>the defined callbacks are based to the ODE <code>solve!</code> function through the keyword argument <code>callbacks</code> as a tuple:</p><pre><code class="language-julia">  solve!(Q, lsrk; timeend = finaltime,
         callbacks = (cb_store_norm, cb_vtk, cb_info))</code></pre><p>The remainder of the function is the same as above</p><pre><code class="language-julia">  filename = @sprintf(&quot;finalsolution_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))

  Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
    exactsolution!(dim, Qin, finaltime, x, y, z)
  end
  error = euclidean_distance(Q, Qe)
  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Run with
                   dim              = %d
                   Ne               = %d
                   polynomial order = %d
                   error            = %e
                   &quot;&quot;&quot;, dim, Ne, polynomialorder, error)
  end
end</code></pre><pre><code class="language-none">┌ Info: Update
│ simtime = 1.8281249999999960e-01
│ runtime = 00:00:00
└ norm(Q) = 2.2795853021360446e+00
┌ Info: Update
│ simtime = 4.0312500000000151e-01
│ runtime = 00:00:01
└ norm(Q) = 2.2795853018904570e+00
┌ Info: Update
│ simtime = 6.2343750000000464e-01
│ runtime = 00:00:02
└ norm(Q) = 2.2795853016451102e+00
┌ Info: Update
│ simtime = 8.3750000000000768e-01
│ runtime = 00:00:03
└ norm(Q) = 2.2795853014066281e+00
┌ Info: Run with
│ dim              = 2
│ Ne               = 20
│ polynomial order = 4
└ error            = 3.219188e-06</code></pre><h3><a class="nav-anchor" id="Computing-rates-and-errors-1" href="#Computing-rates-and-errors-1">Computing rates and errors</a></h3><p>If the above code is put in a loop over increasing <code>Ne</code> then a rate of convergence for the scheme can be established which we expect to be on the order of the polynomial order plus <span>$\sim 1/2$</span>.</p><pre><code class="language-julia">let
  mpicomm = MPI.COMM_WORLD
  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)

  dim = 2
  polynomialorder = 4
  finaltime = 1.0

  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Running with
                   dim              = %d
                   polynomial order = %d
                   &quot;&quot;&quot;, dim, polynomialorder)
  end

  base_Ne = 5
  lvl_error = zeros(4) # number of levels to compute is length(lvl_error)
  for lvl = 1:length(lvl_error)
    # `Ne` for this mesh level
    Ne = base_Ne * 2^(lvl-1)
    spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)

    Q = MPIStateArray(spatialdiscretization, initialcondition!)
    h = 1 / Ne
    CFL = h / maximum(abs.(uvec[1:dim]))
    dt = CFL / polynomialorder^2
    lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)

    solve!(Q, lsrk; timeend = finaltime)

    Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
      exactsolution!(dim, Qin, finaltime, x, y, z)
    end

    lvl_error[lvl] = euclidean_distance(Q, Qe)
    msg =  @sprintf   &quot;Level      = %d&quot; lvl
    msg *= @sprintf &quot;\nNe               = %d&quot; Ne
    msg *= @sprintf &quot;\nerror            = %.4e&quot; lvl_error[lvl]
    if lvl &gt; 1
      rate = log2(lvl_error[lvl-1]) - log2(lvl_error[lvl])
      msg *= @sprintf &quot;\nconvergence rate = %.4e&quot; rate
    end
    with_logger(mpi_logger) do
      @info msg
    end
  end
end</code></pre><pre><code class="language-none">┌ Info: Running with
│ dim              = 2
└ polynomial order = 4
┌ Info: Level      = 1
│ Ne               = 5
└ error            = 5.1353e-03
┌ Info: Level      = 2
│ Ne               = 10
│ error            = 1.0321e-04
└ convergence rate = 5.6369e+00
┌ Info: Level      = 3
│ Ne               = 20
│ error            = 3.2192e-06
└ convergence rate = 5.0027e+00
┌ Info: Level      = 4
│ Ne               = 40
│ error            = 1.0168e-07
└ convergence rate = 4.9846e+00</code></pre><h2><a class="nav-anchor" id="ex_001_periodic_advection-plain-program-1" href="#ex_001_periodic_advection-plain-program-1">Plain Program</a></h2><p>Below follows a version of the program without any comments. The file is also available here: <a href="ex_001_periodic_advection.jl">ex_001_periodic_advection.jl</a></p><pre><code class="language-julia">using MPI
using CLIMA.Mesh.Topologies
using CLIMA.Mesh.Grids
using CLIMA.DGBalanceLawDiscretizations
using CLIMA.MPIStateArrays
using CLIMA.LowStorageRungeKuttaMethod
using CLIMA.ODESolvers
using CLIMA.GenericCallbacks
using CLIMA.VTK
using LinearAlgebra
using Logging
using Dates
using Printf
using StaticArrays

MPI.Initialized() || MPI.Init()

const uvec = (1, 2, 3)

function advectionflux!(F, state, _...)
  DFloat = eltype(state) # get the floating point type we are using
  @inbounds begin
    q = state[1]
    F[:, 1] = SVector{3, DFloat}(uvec) * q
  end
end

function upwindflux!(fs, nM, stateM, viscM, auxM, stateP, viscP, auxP, t)
  DFloat = eltype(fs)
  @inbounds begin
    # determine the advection speed and direction
    un = dot(nM, DFloat.(uvec))
    qM = stateM[1]
    qP = stateP[1]
    # Determine which state is &quot;upwind&quot; of the minus side
    fs[1] = un ≥ 0 ? un * qM : un * qP
  end
end

function initialcondition!(Q, x_1, x_2, x_3, _...)
  @inbounds Q[1] = exp(sin(2π * x_1)) * exp(sin(2π * x_2)) * exp(sin(2π * x_3))
end

function exactsolution!(dim, Q, t, x_1, x_2, x_3, _...)
  @inbounds begin
    DFloat = eltype(Q)

    # trace back the point (x_1, x_2, x_3) in the velocity field and
    # determine where in our &quot;original&quot; [0, L_1] X [0, L_2] X [0, L_3] domain
    # this point is located
    y_1 = mod(x_1 - DFloat(uvec[1]) * t, 1)
    y_2 = mod(x_2 - DFloat(uvec[2]) * t, 1)

    # if we are really just 2-D we do not want to change the x_3 coordinate
    y_3 = dim == 3 ? mod(x_3 - DFloat(uvec[3]) * t, 1) : x_3

    initialcondition!(Q, y_1, y_2, y_3)
  end
end

function setupDG(mpicomm, dim, Ne, polynomialorder, DFloat=Float64,
                 ArrayType=Array)

  @assert ArrayType === Array

  brickrange = (range(DFloat(0); length=Ne+1, stop=1), # x_1 corner locations
                range(DFloat(0); length=Ne+1, stop=1), # x_2 corner locations
                range(DFloat(0); length=Ne+1, stop=1)) # x_3 corner locations

  periodicity = (true, true, true)

  topology = BrickTopology(mpicomm, brickrange[1:dim];
                           periodicity=periodicity[1:dim])

  grid = DiscontinuousSpectralElementGrid(topology; polynomialorder =
                                          polynomialorder, FloatType = DFloat,
                                          DeviceArray = ArrayType,)

  spatialdiscretization = DGBalanceLaw(grid = grid, length_state_vector = 1,
                                       flux! = advectionflux!,
                                       numerical_flux! = upwindflux!)

end

let

  mpicomm = MPI.COMM_WORLD

  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)

  dim = 2

  Ne = 20

  polynomialorder = 4

  spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)

  Q = MPIStateArray(spatialdiscretization, initialcondition!)

  filename = @sprintf(&quot;initialcondition_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))

  h = 1 / Ne                           # element size
  CFL = h / maximum(abs.(uvec[1:dim])) # time to cross the element once
  dt = CFL / polynomialorder^2         # DG time step scaling (for this
                                       # particular RK scheme could go with a
                                       # factor of ~2 larger time step)
  lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)

  finaltime = 1.0
  solve!(Q, lsrk; timeend = finaltime)

  filename = @sprintf(&quot;finalsolution_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))

  Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
    exactsolution!(dim, Qin, finaltime, x, y, z)
  end

  error = euclidean_distance(Q, Qe)
  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Run with
                   dim              = %d
                   Ne               = %d
                   polynomial order = %d
                   error            = %e
                   &quot;&quot;&quot;, dim, Ne, polynomialorder, error)
  end
end

let

  mpicomm = MPI.COMM_WORLD
  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)
  dim = 2
  Ne = 20
  polynomialorder = 4
  spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)
  Q = MPIStateArray(spatialdiscretization, initialcondition!)
  filename = @sprintf(&quot;initialcondition_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))
  h = 1 / Ne
  CFL = h / maximum(abs.(uvec[1:dim]))
  dt = CFL / polynomialorder^2
  lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)
  finaltime = 1.0

  store_norm_index = 0
  normQ = Array{Float64}(undef, ceil(Int, finaltime / dt))
  function cb_store_norm()
    store_norm_index += 1
    normQ[store_norm_index] = norm(Q)
    nothing
  end

  vtk_step = 0
  mkpath(&quot;vtk&quot;)
  cb_vtk = GenericCallbacks.EveryXSimulationSteps(20) do
    vtk_step += 1
    filename = @sprintf(&quot;vtk/advection_mpirank%04d_step%04d&quot;,
                         MPI.Comm_rank(mpicomm), vtk_step)
    writevtk(filename, Q, spatialdiscretization,
                                         (&quot;q&quot;,))
    nothing
  end

  starttime = Ref(now())
  cb_info = GenericCallbacks.EveryXWallTimeSeconds(1, mpicomm) do (init=false)
    if init
      starttime[] = now()
    else
      with_logger(mpi_logger) do
        @info @sprintf(&quot;&quot;&quot;Update
                       simtime = %.16e
                       runtime = %s
                       norm(Q) = %.16e&quot;&quot;&quot;, ODESolvers.gettime(lsrk),
                       Dates.format(convert(Dates.DateTime,
                                            Dates.now()-starttime[]),
                                    Dates.dateformat&quot;HH:MM:SS&quot;),
                       norm(Q))
      end
    end
  end

  solve!(Q, lsrk; timeend = finaltime,
         callbacks = (cb_store_norm, cb_vtk, cb_info))

  filename = @sprintf(&quot;finalsolution_mpirank%04d&quot;, MPI.Comm_rank(mpicomm))
  writevtk(filename, Q, spatialdiscretization,
                                       (&quot;q&quot;,))

  Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
    exactsolution!(dim, Qin, finaltime, x, y, z)
  end
  error = euclidean_distance(Q, Qe)
  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Run with
                   dim              = %d
                   Ne               = %d
                   polynomial order = %d
                   error            = %e
                   &quot;&quot;&quot;, dim, Ne, polynomialorder, error)
  end
end

let
  mpicomm = MPI.COMM_WORLD
  mpi_logger = ConsoleLogger(MPI.Comm_rank(mpicomm) == 0 ? stderr : devnull)

  dim = 2
  polynomialorder = 4
  finaltime = 1.0

  with_logger(mpi_logger) do
    @info @sprintf(&quot;&quot;&quot;Running with
                   dim              = %d
                   polynomial order = %d
                   &quot;&quot;&quot;, dim, polynomialorder)
  end

  base_Ne = 5
  lvl_error = zeros(4) # number of levels to compute is length(lvl_error)
  for lvl = 1:length(lvl_error)
    # `Ne` for this mesh level
    Ne = base_Ne * 2^(lvl-1)
    spatialdiscretization = setupDG(mpicomm, dim, Ne, polynomialorder)

    Q = MPIStateArray(spatialdiscretization, initialcondition!)
    h = 1 / Ne
    CFL = h / maximum(abs.(uvec[1:dim]))
    dt = CFL / polynomialorder^2
    lsrk = LSRK54CarpenterKennedy(spatialdiscretization, Q; dt = dt, t0 = 0)

    solve!(Q, lsrk; timeend = finaltime)

    Qe = MPIStateArray(spatialdiscretization) do Qin, x, y, z, aux
      exactsolution!(dim, Qin, finaltime, x, y, z)
    end

    lvl_error[lvl] = euclidean_distance(Q, Qe)
    msg =  @sprintf   &quot;Level      = %d&quot; lvl
    msg *= @sprintf &quot;\nNe               = %d&quot; Ne
    msg *= @sprintf &quot;\nerror            = %.4e&quot; lvl_error[lvl]
    if lvl &gt; 1
      rate = log2(lvl_error[lvl-1]) - log2(lvl_error[lvl])
      msg *= @sprintf &quot;\nconvergence rate = %.4e&quot; rate
    end
    with_logger(mpi_logger) do
      @info msg
    end
  end
end

# This file was generated using Literate.jl, https://github.com/fredrikekre/Literate.jl</code></pre><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../../../BalanceLawOverview.html"><span class="direction">Previous</span><span class="title">DG Balance Law Method</span></a><a class="next" href="ex_002_solid_body_rotation.html"><span class="direction">Next</span><span class="title">Example 002: Solid Body Rotation</span></a></footer></article></body></html>
